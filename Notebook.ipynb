{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# https://github.com/serengil/tensorflow-101/blob/master/python/Matlab-Model-to-Keras.ipynb\n",
    "# https://sefiks.com/2019/07/15/how-to-convert-matlab-models-to-keras/\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from keras import layers\n",
    "import scipy.io as sio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Sat Feb 25 03:27:35 2017', '__version__': '1.0', '__globals__': [], 'word_size': array([[10000]], dtype=uint16), 'wordcnt': array([[  9,  55,  23, ..., 215,   6,  18]], dtype=uint16), 'totalimg': array([[5123]], dtype=uint16)}\n"
     ]
    }
   ],
   "source": [
    "# prepare data\n",
    "working_catalog = r\"C:\\Users\\miugi\\Downloads\"\n",
    "net_path = os.path.join(working_catalog, \"imagenet-vgg-m-1024.mat\")\n",
    "network_mat = sio.loadmat(net_path, matlab_compatible=False, struct_as_record=False)\n",
    "reverse_path = os.path.join(working_catalog, \"reverse_10000.mat\")\n",
    "reverse = sio.loadmat(reverse_path, matlab_compatible=False, struct_as_record=False)\n",
    "word_path = os.path.join(working_catalog, \"word_10000.mat\")\n",
    "word = sio.loadmat(word_path)\n",
    "\n",
    "print(reverse)\n",
    "#TODO what about network_mat[\"meta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1']\n",
      "['relu1']\n",
      "['norm1']\n",
      "['pool1']\n",
      "['conv2']\n",
      "['relu2']\n",
      "['norm2']\n",
      "['pool2']\n",
      "['conv3']\n",
      "['relu3']\n",
      "['conv4']\n",
      "['relu4']\n",
      "['conv5']\n",
      "['relu5']\n",
      "['pool5']\n",
      "['fc6']\n",
      "['relu6']\n",
      "['fc7']\n",
      "['relu7']\n",
      "['fc8']\n",
      "['prob']\n"
     ]
    }
   ],
   "source": [
    "ref_model_layers = network_mat['layers'][0]\n",
    "num_of_ref_model_layers = ref_model_layers.shape[0]\n",
    "for layer in ref_model_layers:\n",
    "    print(layer[0][0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 :  (7, 7, 3, 96)\n",
      "conv2 :  (5, 5, 96, 256)\n",
      "conv3 :  (3, 3, 256, 512)\n",
      "conv4 :  (3, 3, 512, 512)\n",
      "conv5 :  (3, 3, 512, 512)\n",
      "fc6 :  (6, 6, 512, 4096)\n",
      "fc7 :  (1, 1, 4096, 1024)\n",
      "fc8 :  (1, 1, 1024, 1000)\n"
     ]
    }
   ],
   "source": [
    "for i in range(ref_model_layers.shape[0]):\n",
    "    ref_model_layer = ref_model_layers[i][0,0].name[0]\n",
    "    try:\n",
    "        weights = ref_model_layers[i][0,0].weights[0,0]\n",
    "        print(ref_model_layer,\": \",weights.shape)\n",
    "    except:\n",
    "        #print(ref_model_layer)\n",
    "        print(\"\",end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZeroPadding2D((1,1))\n",
      "Convolution2D( 96 , ( 7 ,  7 ), name=' conv1 ')\n",
      "Activation('relu', name= relu1\n",
      "--> norm1\n",
      "MaxPooling2D((2,2), strides=(2,2), name= pool1 )\n",
      "ZeroPadding2D((1,1))\n",
      "Convolution2D( 256 , ( 5 ,  5 ), name=' conv2 ')\n",
      "Activation('relu', name= relu2\n",
      "--> norm2\n",
      "MaxPooling2D((2,2), strides=(2,2), name= pool2 )\n",
      "ZeroPadding2D((1,1))\n",
      "Convolution2D( 512 , ( 3 ,  3 ), name=' conv3 ')\n",
      "Activation('relu', name= relu3\n",
      "ZeroPadding2D((1,1))\n",
      "Convolution2D( 512 , ( 3 ,  3 ), name=' conv4 ')\n",
      "Activation('relu', name= relu4\n",
      "ZeroPadding2D((1,1))\n",
      "Convolution2D( 512 , ( 3 ,  3 ), name=' conv5 ')\n",
      "Activation('relu', name= relu5\n",
      "MaxPooling2D((2,2), strides=(2,2), name= pool5 )\n",
      "Convolution2D( 4096 , ( 6 ,  6 ), name=' fc6 ')\n",
      "Activation('relu', name= relu6\n",
      "Convolution2D( 1024 , ( 1 ,  1 ), name=' fc7 ')\n",
      "Activation('relu', name= relu7\n",
      "Convolution2D( 1000 , ( 1 ,  1 ), name=' fc8 ')\n",
      "--> prob\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "for i in range(num_of_ref_model_layers):\n",
    "    ref_model_layer = ref_model_layers[i][0][0].name[0]\n",
    "    if ref_model_layer.find(\"conv\") == 0 or ref_model_layer.find(\"fc\") == 0:\n",
    "        weights = ref_model_layers[i][0,0].weights\n",
    "        weights_shape = weights[0][0].shape\n",
    "        #print(\":\", weights_shape)\n",
    "        filter_x = weights_shape[0]; filter_y = weights_shape[1]\n",
    "        number_of_filters = weights_shape[3]\n",
    "        \n",
    "        if ref_model_layer.find(\"conv\") == 0:\n",
    "            print(\"ZeroPadding2D((1,1))\")\n",
    "            if i == 0:\n",
    "                model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "            else:\n",
    "                model.add(ZeroPadding2D((1,1)))\n",
    "        \n",
    "        print(\"Convolution2D(\",number_of_filters,\", (\",filter_x,\", \",filter_y,\"), name='\",ref_model_layer,\"')\")\n",
    "        model.add(Convolution2D(number_of_filters, (filter_x, filter_y), name= ref_model_layer))\n",
    "        \n",
    "    else:\n",
    "        if ref_model_layer.find(\"relu\") == 0:\n",
    "            print(\"Activation('relu', name=\",ref_model_layer)\n",
    "            model.add(Activation('relu', name=ref_model_layer))\n",
    "        elif ref_model_layer.find(\"dropout\") == 0:\n",
    "            print(\"Dropout(0.5, name=\",ref_model_layer,\")\")\n",
    "            model.add(Dropout(0.5, name=ref_model_layer))\n",
    "        elif ref_model_layer.find(\"pool\") == 0:\n",
    "            print(\"MaxPooling2D((2,2), strides=(2,2), name=\",ref_model_layer,\")\")\n",
    "            model.add(MaxPooling2D((2,2), strides=(2,2), name=ref_model_layer))\n",
    "        elif ref_model_layer.find(\"softmax\") == 0:\n",
    "            print(\"Activation('softmax', name=\",ref_model_layer,\")\")\n",
    "            model.add(Activation('softmax', name=ref_model_layer))\n",
    "        else:\n",
    "            print(\"-->\",ref_model_layer)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1 :  (7, 7, 3, 96)\n",
      "conv2 :  (5, 5, 96, 256)\n",
      "conv3 :  (3, 3, 256, 512)\n",
      "conv4 :  (3, 3, 512, 512)\n",
      "conv5 :  (3, 3, 512, 512)\n",
      "fc6 :  (6, 6, 512, 4096)\n",
      "fc7 :  (1, 1, 4096, 1024)\n",
      "fc8 :  (1, 1, 1024, 1000)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    layer_name = layer.name\n",
    "    try:\n",
    "        print(layer_name,\": \",layer.weights[0].shape)\n",
    "    except:\n",
    "        print(\"\",end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_layer_names = [layer.name for layer in model.layers]\n",
    "num_of_ref_model_layers = ref_model_layers.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 .  conv1\n",
      "4 .  conv2\n",
      "8 .  conv3\n",
      "10 .  conv4\n",
      "12 .  conv5\n",
      "15 .  fc6\n",
      "17 .  fc7\n",
      "19 .  fc8\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_of_ref_model_layers):\n",
    "    ref_model_layer = ref_model_layers[i][0,0].name[0]\n",
    "    if ref_model_layer in base_model_layer_names:\n",
    "        #we just need to set convolution and fully connected weights\n",
    "        if ref_model_layer.find(\"conv\") == 0 or ref_model_layer.find(\"fc\") == 0:\n",
    "            print(i,\". \",ref_model_layer)\n",
    "            base_model_index = base_model_layer_names.index(ref_model_layer)\n",
    "            \n",
    "            weights = ref_model_layers[i][0,0].weights[0,0]\n",
    "            bias = ref_model_layers[i][0,0].weights[0,1]\n",
    "            \n",
    "            model.layers[base_model_index].set_weights([weights, bias[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to load a weight file containing 8 layers into a model with 16 layers.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0b3f193ad6fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m tf.keras.applications.VGG16(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weights.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[0;32m    222\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[0;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[0;32m   2233\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2234\u001b[1;33m         \u001b[0mhdf5_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2236\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m    683\u001b[0m   \u001b[0mlayer_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_layer_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m     raise ValueError('You are trying to load a weight file '\n\u001b[0m\u001b[0;32m    686\u001b[0m                      \u001b[1;34m'containing '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                      \u001b[1;34m' layers into a model with '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to load a weight file containing 8 layers into a model with 16 layers."
     ]
    }
   ],
   "source": [
    "tf.keras.applications.VGG16(\n",
    "    include_top=True,\n",
    "    weights='weights.h5',\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
